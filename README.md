# Google Maps Lead Scraper â€“ Complete Demo

> **Automate your B2B prospection in seconds, not hours.**

A production-ready, educational example showing how to build a lead generation tool that extracts business data from Google Maps and presents it in a clean, actionable interface.

---

## ğŸ“‹ What's in this repo

- **`business_context.json`** â€“ Market data, target segments, pricing, legal framework, and business strategy (reusable JSON)
- **`app.py`** â€“ Flask backend with API endpoint and HTML interface (fully functional demo)
- **`README.md`** â€“ This file

---

## ğŸ¯ Core Value Proposition

| Metric | Before (Manual) | After (Automated) |
|--------|-----------------|-------------------|
| **Time to collect 50 leads** | 4-6 hours | 2 minutes |
| **Data quality** | High error rate (manual copy/paste) | Perfect accuracy (structured data) |
| **Cost to prospect 500 businesses** | ~$500 (human time) | ~$10 (server) |
| **Scalability** | Very difficult | Trivial |

---

## ğŸš€ Quick Start

### 1. Install dependencies

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install flask
```

### 2. Run the app

```bash
python app.py
```

Then open:

```
http://127.0.0.1:5000/
```

### 3. Try it out

1. Type `plumber` in the "Business Type" field
2. Type `Rennes` in the "Location" field
3. Click **"Generate Leads"**
4. See mock leads appear (in production, these would be real data from Google Maps)
5. Click **"Export CSV"** or **"Export JSON"**

---

## ğŸ“Š API Reference

### `POST /api/scrape`

**Request:**

```json
{
  "query": "plumber",
  "location": "Rennes"
}
```

**Response:**

```json
{
  "query": "plumber",
  "location": "Rennes",
  "timestamp": "2026-01-15T18:30:00Z",
  "leads": [
    {
      "name": "Plumber Alpha - Rennes",
      "address": "12 Rue des Exemples, Rennes",
      "phone": "+33 2 99 00 00 01",
      "website": "https://example-alpha.com",
      "email": "contact@example-alpha.com",
      "rating": 4.7,
      "review_count": 128,
      "category": "Plumber"
    }
  ]
}
```

---

## ğŸ¨ UI Features

- **Dark theme** â€“ Modern, easy on the eyes
- **Before/After comparison** â€“ Visual impact of automation
- **Live search form** â€“ Type and get results instantly
- **Export to CSV & JSON** â€“ Ready for CRM or spreadsheet import
- **Responsive design** â€“ Works on desktop, tablet, mobile

---

## âš™ï¸ How to adapt this for production

### Option 1: Use Google Places API (Recommended for accuracy)

```python
from google.maps import places_sdk

def get_real_leads(query: str, location: str):
    client = places_sdk.PlacesClient(api_key="YOUR_API_KEY")
    results = client.search_nearby(
        query=query,
        location=location,
        radius=50000  # 50km
    )
    return [
        {
            "name": place.name,
            "address": place.formatted_address,
            "phone": place.phone_number,
            "website": place.website,
            "email": extract_email_from_website(place.website),
            "rating": place.rating,
            "review_count": place.review_count,
            "category": place.types[0]
        }
        for place in results
    ]
```

### Option 2: Use Selenium/Playwright (More complex but fully automated)

```python
from selenium import webdriver

def scrape_google_maps(query: str, location: str):
    driver = webdriver.Chrome()
    driver.get(f"https://maps.google.com/maps/search/{query}+{location}")
    
    # Wait, scroll, parse HTML...
    # Extract name, address, phone, ratings
    
    driver.quit()
    return results
```

### Option 3: Use third-party API (Easiest)

```python
import requests

def get_leads_from_scrap_io(query: str, location: str):
    response = requests.post(
        "https://api.scrap.io/search",
        json={"query": query, "location": location},
        headers={"Authorization": "Bearer YOUR_API_KEY"}
    )
    return response.json()["leads"]
```

### Option 4: Mix approaches

Use the official API for basic data, Selenium for enrichment (reviews, photos), and manual verification for quality.

---

## ğŸ”’ Legal & GDPR Compliance

This demo only uses **publicly available business data** (name, address, phone). To run this ethically in production:

âœ… **DO:**
- Collect only **public business data** (not personal emails)
- Use data for **legitimate B2B prospection** (not spam)
- Respect **rate limits** (don't hammer servers)
- Provide **opt-out mechanisms** (easy unsubscribe)
- Store data **securely** with limited retention
- Document your **data processing activities** (for GDPR audits)

âŒ **DON'T:**
- Scrape **consumer (B2C) data** without consent
- Use data for **unsolicited mass email campaigns**
- Bypass **rate limiting or CAPTCHAs**
- Sell data to **third parties** without permission
- Keep data **indefinitely** (set expiration dates)

**References:**
- GDPR Article 6 (Legitimate interest basis for B2B)
- GDPR Article 21 (Right to object)
- French CNIL guidelines on prospection

---

## ğŸ’° Pricing Strategy

Use `business_context.json` to reference these benchmarks:

| Service | Price | Effort |
|---------|-------|--------|
| One-off basic script | â‚¬500â€“1,500 | 1â€“3 days |
| Full solution with UI | â‚¬2,500â€“5,000 | 5â€“10 days |
| Training session (4â€“8h) | â‚¬500â€“800 | 1 day |
| Monthly maintenance | â‚¬150â€“300 | 2â€“4h/month |

**Positioning:**
- **50x cheaper** than hiring an agency (which costs â‚¬56kâ€“70k/year)
- **2â€“5x more customizable** than SaaS tools (Scrap.io, Octoparse)
- **Faster** to launch (1â€“2 weeks vs 3â€“6 months)

---

## ğŸ“ˆ Target Segments

Use `business_context.json` to understand who to sell to:

1. **Marketing agencies** â€“ Need tools for client prospection
2. **SMBs in trades/construction** â€“ Need local lead generation
3. **Freelancers & consultants** â€“ Need automated prospect pipelines
4. **Real estate / retail** â€“ Need location-based market analysis

Each segment has different pain points, budget, and use cases. Tailor your pitch accordingly.

---

## ğŸ“š Project Structure

```
.
â”œâ”€â”€ app.py                    # Flask app (HTML + API endpoint)
â”œâ”€â”€ business_context.json     # Reusable market data & strategy
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ requirements.txt          # Python dependencies (optional)
â””â”€â”€ .gitignore               # Git ignore file
```

### Future additions (optional)

```
â”œâ”€â”€ config.py                # Configuration (API keys, etc)
â”œâ”€â”€ scraper.py              # Real scraping logic
â”œâ”€â”€ models.py               # Database models (SQLAlchemy)
â”œâ”€â”€ tests/                  # Unit tests
â”œâ”€â”€ docker-compose.yml      # Docker setup for local dev
â”œâ”€â”€ Dockerfile              # Docker image for production
â”œâ”€â”€ deploy/                 # Render/Heroku deployment config
â””â”€â”€ docs/                   # Extended documentation
```

---

## ğŸ› ï¸ Tech Stack

- **Backend:** Python 3.10+ with Flask
- **Frontend:** Vanilla HTML / CSS / JavaScript (no dependencies)
- **Data format:** JSON (human-readable, easy to parse)
- **Deployment:** Render, Heroku, DigitalOcean, or any Python host

---

## ğŸ“¦ Dependencies

Create a `requirements.txt` if deploying to production:

```
flask==2.3.0
requests==2.31.0
python-dotenv==1.0.0
gunicorn==21.2.0
```

Then install with:

```bash
pip install -r requirements.txt
```

---

## ğŸš¢ Deployment

### Option 1: Deploy to Render (Free tier available)

1. Push code to GitHub
2. Connect GitHub repo to Render
3. Set environment variables
4. Click "Deploy"

### Option 2: Deploy to Heroku

```bash
heroku create my-scraper-app
git push heroku main
heroku config:set DEBUG=False
```

### Option 3: Deploy to DigitalOcean App Platform

1. Create App
2. Connect GitHub repo
3. Set port to 5000
4. Deploy

### Production checklist

- [ ] Use environment variables for secrets (`.env` file)
- [ ] Set `debug=False` in Flask
- [ ] Use a production WSGI server (Gunicorn)
- [ ] Add rate limiting to API endpoints
- [ ] Set up logging and error tracking
- [ ] Test CSV/JSON export thoroughly
- [ ] Document API for clients

---

## ğŸ“ˆ Growth Roadmap

### Month 1â€“2

- [ ] Validate product-market fit with 3â€“5 pilot clients
- [ ] Collect testimonials and case studies
- [ ] Publish GitHub demo with clean code

### Month 3â€“6

- [ ] Convert pilots to monthly maintenance contracts
- [ ] Build portfolio of real projects
- [ ] Create tutorial videos

### Month 7â€“12

- [ ] Offer white-label solution to agencies
- [ ] Build internal CRM integration (HubSpot, Pipedrive)
- [ ] Consider SaaS version with self-service signup

### Year 2+

- [ ] Scale to 20â€“30 recurring clients
- [ ] Launch SaaS product for mass market
- [ ] Hire developer to handle project overflow

---

## ğŸ’¡ Before/After: The Business Impact

### Before automation (typical workflow)

1. Open Google Maps
2. Type "plumber in Rennes"
3. Scroll, zoom, click each business
4. Copy/paste: name, address, phone, website
5. Paste into Excel
6. Repeat 100+ times (6â€“8 hours)
7. Final list has ~10% errors
8. Manually filter out non-local businesses
9. Try to find email addresses elsewhere
10. Finally, start prospection (next day)

**Time cost:** 8â€“10 hours for 100 leads  
**Quality:** Mediocre (copy/paste errors)  
**Scalability:** Impossible (too manual)

### After automation (this tool)

1. Open the app
2. Type "plumber" + "Rennes"
3. Click "Generate Leads"
4. Get 50â€“100 leads in **2 minutes**, structured with:
   - Name, address, phone, website, email
   - Rating, review count, category
5. Click "Export CSV"
6. Import directly into CRM
7. Start outreach immediately

**Time cost:** 5 minutes for 100 leads  
**Quality:** Perfect (no copy/paste errors)  
**Scalability:** Trivial (run again next week)

**ROI:** If your time is worth â‚¬50/hour, you save â‚¬400 per 100 leads. Selling this tool for â‚¬1,000â€“2,500 means it pays for itself on the first use.

---

## ğŸ¤ Contributing

This is a demo project. Feel free to fork, adapt, and improve.

Suggestions:
- Add real scraping (API or Selenium)
- Build CRM integrations
- Create scheduling (recurring scrapes)
- Add filtering (by rating, review count, etc.)
- Build a dashboard

---

## ğŸ“ License

MIT License â€“ Use freely for commercial or personal projects.

---

## ğŸ“ Questions?

Refer to `business_context.json` for:
- Market sizing and TAM
- Pricing benchmarks
- Legal guidelines
- Target segment details
- Competitive positioning

---

## ğŸ“ Learning Resources

- [Google Places API Docs](https://developers.google.com/maps/documentation/places/web-service)
- [Selenium Python Tutorial](https://www.selenium.dev/documentation/webdriver/getting_started/)
- [Playwright Python Docs](https://playwright.dev/python/)
- [Flask Quick Start](https://flask.palletsprojects.com/)
- [GDPR Compliance for Developers](https://gdpr-info.eu/)

---

**Made with â¤ï¸ by a Python freelancer transitioning from gardening to software development.**

*Demo created: January 2026 | Updated: 2026-01-15*
